{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data ...\n",
      "40000, 40000\n",
      "[\"love the staff, love the meat, love the place. prepare for a long line around lunch or dinner hours. they ask you how you want you meat, lean or something maybe, i can't remember. just say you don't want it too fatty. get a half sour pickle and a hot pepper. hand cut french fries too.\", \"super simple place but amazing nonetheless. it's been around since the 30's and they still serve the same thing they started with: a bologna and salami sandwich with mustard. staff was very helpful and friendly.\"]\n",
      "['5', '5', '5', '5', '4']\n",
      "Development data ...\n",
      "5000, 5000\n"
     ]
    }
   ],
   "source": [
    "# Load packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "# Load data\n",
    "trn_texts = open(\"trn-reviews.txt\").read().strip().lower().split(\"\\n\")\n",
    "trn_labels = open(\"trn-labels.txt\").read().strip().lower().split(\"\\n\")\n",
    "print(\"Training data ...\")\n",
    "print(\"%d, %d\" % (len(trn_texts), len(trn_labels)))\n",
    "print(trn_texts[:2])\n",
    "print(trn_labels[:5])\n",
    "\n",
    "dev_texts = open(\"dev-reviews.txt\").read().strip().split(\"\\n\")\n",
    "dev_labels = open(\"dev-labels.txt\").read().strip().split(\"\\n\")\n",
    "print(\"Development data ...\")\n",
    "print(\"%d, %d\" % (len(dev_texts), len(dev_labels)))\n",
    "dev_tokens = WordPunctTokenizer().tokenize_sents(dev_texts)\n",
    "trn_tokens = WordPunctTokenizer().tokenize_sents(trn_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def loadGloveModel(gloveFile):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r', encoding='utf-8')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print(\"Done.\",len(model),\" words loaded!\")\n",
    "    return model\n",
    "glove6B = loadGloveModel('glove.6B/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentenceTokensToVectors(sentenceTokens, model):\n",
    "    trn_sentence_vectors = []\n",
    "    for tokens in sentenceTokens:\n",
    "        sentenceVector = np.zeros(50)\n",
    "        tokenCount = 0\n",
    "        for token in tokens:\n",
    "            tokenCount += 1\n",
    "            if token in glove6B:\n",
    "                sentenceVector += glove6B[token]\n",
    "            else:\n",
    "                sentenceVector += glove6B['unk']\n",
    "        if tokenCount > 0:\n",
    "            sentenceVector /= tokenCount\n",
    "        trn_sentence_vectors.append(sentenceVector)\n",
    "    return np.array(trn_sentence_vectors)\n",
    "trn_sentence_vectors = sentenceTokensToVectors(trn_tokens, glove6B)\n",
    "dev_sentence_vectors = sentenceTokensToVectors(dev_tokens, glove6B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Logistic Regression with embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\james\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.515975\n",
      "Dev accuracy = %f 0.5322\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define a LR classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(trn_sentence_vectors, trn_labels)\n",
    "\n",
    "# Measure the performance on training and dev data\n",
    "print(\"Training accuracy = %f\" % classifier.score(trn_sentence_vectors, trn_labels))\n",
    "print(\"Dev accuracy = %f\", classifier.score(dev_sentence_vectors, dev_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 CountVectorizer with embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 686)\n"
     ]
    }
   ],
   "source": [
    "choice = 3\n",
    "\n",
    "if choice == 1:\n",
    "    print(\"Preprocessing without any feature selection\")\n",
    "    vectorizer = CountVectorizer(lowercase=False)\n",
    "    # vocab size 77166\n",
    "elif choice == 2:\n",
    "    print(\"Lowercasing all the tokens\")\n",
    "    vectorizer = CountVectorizer(lowercase=True)\n",
    "    # vocab size 60610\n",
    "elif choice == 3:\n",
    "    vectorizer = CountVectorizer(lowercase=True, min_df=0.017, max_df=0.95)\n",
    "elif choice == 4:\n",
    "    vectorizer = CountVectorizer(lowercase=True, ngram_range=(1, 2), min_df=0.017, max_df=0.95)\n",
    "else: \n",
    "    raise ValueError(\"Unrecognized value: choice = %d\" % choice)\n",
    "\n",
    "trn_data = vectorizer.fit_transform(trn_texts).toarray()\n",
    "dev_data = vectorizer.transform(dev_texts).toarray()\n",
    "print(dev_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augment data\n",
    "combined_trn_data = np.concatenate((trn_data, trn_sentence_vectors), axis=1)\n",
    "combined_dev_data = np.concatenate((dev_data, dev_sentence_vectors), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\james\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.641750\n",
      "Dev accuracy = %f 0.6314\n"
     ]
    }
   ],
   "source": [
    "# Define a LR classifier default\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(combined_trn_data, trn_labels)\n",
    "\n",
    "# Measure the performance on training and dev data\n",
    "print(\"Training accuracy = %f\" % classifier.score(combined_trn_data, trn_labels))\n",
    "print(\"Dev accuracy = %f\", classifier.score(combined_dev_data, dev_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\james\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.638350\n",
      "Dev accuracy = %f 0.6328\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define a LR classifier\n",
    "classifier = LogisticRegression(penalty='l1', C=0.2)\n",
    "classifier.fit(combined_trn_data, trn_labels)\n",
    "\n",
    "# Measure the performance on training and dev data\n",
    "print(\"Training accuracy = %f\" % classifier.score(combined_trn_data, trn_labels))\n",
    "print(\"Dev accuracy = %f\", classifier.score(combined_dev_data, dev_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
